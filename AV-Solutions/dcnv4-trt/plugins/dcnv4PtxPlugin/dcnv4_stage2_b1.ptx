/*
 * SPDX-FileCopyrightText: Copyright (c) 2023-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 * SPDX-License-Identifier: Apache-2.0
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
 
//
// Generated by LLVM NVPTX Back-End
//

.version 7.1
.target sm_60
.address_size 64

// .globl	dcn_kernel
// __shared_memory__ has been demoted

.visible .entry dcn_kernel(
	.param .u64 dcn_kernel_param_1,
	.param .u64 dcn_kernel_param_12,
	.param .u64 dcn_kernel_param_21
)
{
	.reg .pred 	%p<8>;
	.reg .b16 	%rs<12>;
	.reg .b32 	%r<154>;
	.reg .f32 	%f<14>;
	.reg .b64 	%rd<120>;
	// demoted variable
	.shared .align 64 .b8 __shared_memory__[3456];
	ld.param.u64 	%rd39, [dcn_kernel_param_21];
	ld.param.u64 	%rd40, [dcn_kernel_param_1];
	cvta.to.global.u64 	%rd3, %rd40;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r53, %ctaid.y;
	cvt.s64.s32 	%rd4, %r53;
	shr.s32 	%r54, %r1, 31;
	xor.b32  	%r55, %r54, %r1;
	mul.hi.s32 	%r56, %r55, -1840700269;
	mad.lo.s32 	%r57, %r55, 1, %r56;
	shr.u32 	%r58, %r57, 31;
	shr.s32 	%r59, %r57, 2;
	add.s32 	%r60, %r59, %r58;
	xor.b32  	%r61, %r60, %r54;
	cvt.s64.s32 	%rd5, %r61;
	mov.u32 	%r62, %tid.x;
	cvt.s64.s32 	%rd6, %r62;
	shr.s32 	%r63, %r62, 31;
	xor.b32  	%r64, %r63, %r62;
	cvt.s64.s32 	%rd7, %r64;
	shr.u64 	%rd42, %rd7, 58;
	add.s64 	%rd43, %rd7, %rd42;
	shr.s64 	%rd44, %rd43, 6;
	cvt.s64.s32 	%rd8, %r63;
	xor.b64  	%rd9, %rd44, %rd8;
	mul.wide.s32 	%rd45, %r1, 2;
	add.s64 	%rd10, %rd9, %rd45;
	and.b64  	%rd11, %rd6, 63;
	setp.gt.u64 	%p1, %rd11, 53;
	shl.b64 	%rd111, %rd6, 3;
	mul.lo.s64 	%rd112, %rd9, 1728;
	mov.u64 	%rd113, __shared_memory__;
	@%p1 bra 	$L__BB0_2;
	ld.param.u64 	%rd41, [dcn_kernel_param_12];
	cvta.to.global.u64 	%rd2, %rd41;
	shl.b64 	%rd47, %rd9, 9;
	sub.s64 	%rd48, %rd111, %rd47;
	mul.lo.s64 	%rd49, %rd10, 12096;
	add.s64 	%rd50, %rd2, %rd49;
	mul.lo.s64 	%rd51, %rd4, 1728;
	add.s64 	%rd52, %rd50, %rd51;
	shl.b64 	%rd53, %rd48, 1;
	add.s64 	%rd54, %rd52, %rd53;
	ld.global.v4.b32 	{%r65, %r66, %r67, %r68}, [%rd54];
	add.s64 	%rd57, %rd113, %rd112;
	add.s64 	%rd58, %rd57, %rd53;
	st.shared.v4.b32 	[%rd58], {%r65, %r66, %r67, %r68};
	ld.global.v4.b32 	{%r69, %r70, %r71, %r72}, [%rd54+864];
	st.shared.v4.b32 	[%rd58+864], {%r69, %r70, %r71, %r72};
$L__BB0_2:
	cvta.to.global.u64 	%rd1, %rd39;
	cvt.u32.u64 	%r77, %rd5;
	bar.sync 	0;
	shr.u64 	%rd61, %rd7, 59;
	add.s64 	%rd62, %rd7, %rd61;
	shr.s64 	%rd63, %rd62, 5;
	xor.b64  	%rd64, %rd63, %rd8;
	shl.b64 	%rd65, %rd64, 8;
	sub.s64 	%rd12, %rd111, %rd65;
	shl.b64 	%rd66, %rd4, 1;
	shr.u64 	%rd67, %rd11, 5;
	or.b64  	%rd13, %rd67, %rd66;
	shr.u64 	%rd68, %rd7, 63;
	add.s64 	%rd69, %rd7, %rd68;
	shr.s64 	%rd70, %rd69, 1;
	xor.b64  	%rd71, %rd70, %rd8;
	mul.lo.s64 	%rd74, %rd67, 864;
	add.s64 	%rd75, %rd112, %rd74;
	mul.lo.s64 	%rd76, %rd71, 54;
	add.s64 	%rd77, %rd75, %rd76;
	add.s64 	%rd78, %rd77, %rd113;
	mul.lo.s64 	%rd79, %rd64, -864;
	add.s64 	%rd80, %rd78, %rd79;
	add.s64 	%rd115, %rd80, 36;
	mul.lo.s64 	%rd81, %rd5, 100352;
	add.s64 	%rd15, %rd3, %rd81;
	mul.lo.s64 	%rd82, %rd64, 864;
	sub.s64 	%rd83, %rd77, %rd82;
	add.s64 	%rd84, %rd83, %rd113;
	add.s64 	%rd114, %rd84, 2;
	shl.b32 	%r78, %r1, 1;
	cvt.u32.u64 	%r79, %rd9;
	add.s32 	%r80, %r78, %r79;
	mul.lo.s32 	%r81, %r77, 14;
	not.b32 	%r82, %r81;
	add.s32 	%r83, %r82, %r80;
	cvt.u64.u32 	%rd17, %r83;
	mov.b32 	%r134, 0;
	mov.u64 	%rd59, 0;
	mov.u32 	%r135, %r134;
	mov.u32 	%r136, %r134;
	mov.u32 	%r137, %r134;
	mov.u64 	%rd116, %rd59;
	bra.uni 	$L__BB0_3;
$L__BB0_13:
	add.s64 	%rd116, %rd116, 1;
	add.s64 	%rd115, %rd115, 6;
	add.s64 	%rd114, %rd114, 12;
	setp.ne.s64 	%p7, %rd116, 3;
	@%p7 bra 	$L__BB0_3;
	bra.uni 	$L__BB0_14;
$L__BB0_3:
	add.s64 	%rd86, %rd13, %rd116;
	cvt.u32.u64 	%r84, %rd86;
	add.s32 	%r85, %r84, -1;
	cvt.rn.f32.s32 	%f1, %r85;
	mov.u64 	%rd117, %rd114;
	mov.u64 	%rd118, %rd115;
	mov.u64 	%rd119, %rd59;
	bra.uni 	$L__BB0_4;
$L__BB0_12:
	mov.f32 	%f11, 0f3F800000;
	sub.rn.f32 	%f12, %f11, %f2;
	sub.rn.f32 	%f13, %f11, %f3;
	cvt.rn.f16.f32 	%rs4, %f2;
	cvt.rn.f16.f32 	%rs5, %f3;
	cvt.rn.f16.f32 	%rs6, %f12;
	cvt.rn.f16.f32 	%rs7, %f13;
	mul.rn.f16 	%rs8, %rs7, %rs6;
	mov.b32 	%r110, {%rs8, %rs8};
	mul.rn.f16x2 	%r111, %r110, %r141;
	mul.rn.f16x2 	%r112, %r110, %r140;
	mul.rn.f16x2 	%r113, %r110, %r139;
	mul.rn.f16x2 	%r114, %r110, %r138;
	mul.rn.f16 	%rs9, %rs5, %rs6;
	mov.b32 	%r115, {%rs9, %rs9};
	fma.rn.f16x2 	%r116, %r115, %r142, %r114;
	fma.rn.f16x2 	%r117, %r115, %r143, %r113;
	fma.rn.f16x2 	%r118, %r115, %r144, %r112;
	fma.rn.f16x2 	%r119, %r115, %r145, %r111;
	mul.rn.f16 	%rs10, %rs4, %rs7;
	mov.b32 	%r120, {%rs10, %rs10};
	fma.rn.f16x2 	%r121, %r120, %r149, %r119;
	fma.rn.f16x2 	%r122, %r120, %r148, %r118;
	fma.rn.f16x2 	%r123, %r120, %r147, %r117;
	fma.rn.f16x2 	%r124, %r120, %r146, %r116;
	mul.rn.f16 	%rs11, %rs5, %rs4;
	mov.b32 	%r125, {%rs11, %rs11};
	fma.rn.f16x2 	%r126, %r125, %r150, %r124;
	fma.rn.f16x2 	%r127, %r125, %r151, %r123;
	fma.rn.f16x2 	%r128, %r125, %r152, %r122;
	fma.rn.f16x2 	%r129, %r125, %r153, %r121;
	fma.rn.f16x2 	%r137, %r10, %r129, %r137;
	fma.rn.f16x2 	%r136, %r10, %r128, %r136;
	fma.rn.f16x2 	%r135, %r10, %r127, %r135;
	fma.rn.f16x2 	%r134, %r10, %r126, %r134;
	add.s64 	%rd119, %rd119, 1;
	add.s64 	%rd118, %rd118, 2;
	add.s64 	%rd117, %rd117, 4;
	setp.ne.s64 	%p6, %rd119, 3;
	@%p6 bra 	$L__BB0_4;
	bra.uni 	$L__BB0_13;
$L__BB0_4:
	ld.shared.b16 	%rs1, [%rd117+-2];
	cvt.f32.f16 	%f4, %rs1;
	add.rn.f32 	%f5, %f1, %f4;
	add.s64 	%rd87, %rd17, %rd119;
	cvt.u32.u64 	%r90, %rd87;
	cvt.rn.f32.s32 	%f6, %r90;
	ld.shared.b16 	%rs2, [%rd117];
	cvt.f32.f16 	%f7, %rs2;
	add.rn.f32 	%f8, %f6, %f7;
	cvt.rmi.f32.f32 	%f9, %f8;
	cvt.rmi.f32.f32 	%f10, %f5;
	cvt.rzi.s32.f32 	%r14, %f9;
	cvt.rzi.s32.f32 	%r91, %f10;
	cvt.s64.s32 	%rd24, %r91;
	mul.wide.s32 	%rd25, %r91, 256;
	mul.wide.s32 	%rd88, %r14, 7168;
	add.s64 	%rd26, %rd15, %rd88;
	shl.b64 	%rd89, %rd25, 1;
	shl.b64 	%rd91, %rd12, 1;
	mov.b32 	%r150, 0;
	max.u32 	%r92, %r91, %r14;
	setp.gt.u32 	%p2, %r92, 13;
	mov.u32 	%r138, %r150;
	mov.u32 	%r139, %r150;
	mov.u32 	%r140, %r150;
	mov.u32 	%r141, %r150;
	@%p2 bra 	$L__BB0_6;
	add.s64 	%rd90, %rd26, %rd89;
	add.s64 	%rd27, %rd90, %rd91;
	ld.global.v4.b32 	{%r138, %r139, %r140, %r141}, [%rd27];
$L__BB0_6:
	cvt.u32.u64 	%r97, %rd24;
	shl.b64 	%rd92, %rd24, 8;
	add.s32 	%r23, %r97, 1;
	add.s64 	%rd28, %rd92, 256;
	shl.b64 	%rd93, %rd28, 1;
	max.u32 	%r98, %r14, %r23;
	setp.gt.u32 	%p3, %r98, 13;
	mov.u32 	%r142, %r150;
	mov.u32 	%r143, %r150;
	mov.u32 	%r144, %r150;
	mov.u32 	%r145, %r150;
	@%p3 bra 	$L__BB0_8;
	add.s64 	%rd94, %rd26, %rd93;
	add.s64 	%rd29, %rd94, %rd91;
	ld.global.v4.b32 	{%r142, %r143, %r144, %r145}, [%rd29];
$L__BB0_8:
	add.s32 	%r32, %r14, 1;
	add.s64 	%rd30, %rd26, 7168;
	max.u32 	%r104, %r97, %r32;
	setp.gt.u32 	%p4, %r104, 13;
	mov.u32 	%r146, %r150;
	mov.u32 	%r147, %r150;
	mov.u32 	%r148, %r150;
	mov.u32 	%r149, %r150;
	@%p4 bra 	$L__BB0_10;
	add.s64 	%rd97, %rd30, %rd89;
	add.s64 	%rd31, %rd97, %rd91;
	ld.global.v4.b32 	{%r146, %r147, %r148, %r149}, [%rd31];
$L__BB0_10:
	ld.shared.b16 	%rs3, [%rd118];
	mov.b32 	%r10, {%rs3, %rs3};
	sub.rn.f32 	%f2, %f8, %f9;
	sub.rn.f32 	%f3, %f5, %f10;
	max.u32 	%r109, %r23, %r32;
	setp.gt.u32 	%p5, %r109, 13;
	mov.u32 	%r151, %r150;
	mov.u32 	%r152, %r150;
	mov.u32 	%r153, %r150;
	@%p5 bra 	$L__BB0_12;
	add.s64 	%rd100, %rd30, %rd93;
	add.s64 	%rd32, %rd100, %rd91;
	ld.global.v4.b32 	{%r150, %r151, %r152, %r153}, [%rd32];
	bra.uni 	$L__BB0_12;
$L__BB0_14:
	mul.lo.s64 	%rd102, %rd10, 7168;
	add.s64 	%rd103, %rd1, %rd102;
	shl.b64 	%rd104, %rd4, 10;
	shl.b64 	%rd105, %rd11, 4;
	and.b64  	%rd106, %rd105, 512;
	or.b64  	%rd107, %rd104, %rd106;
	add.s64 	%rd108, %rd103, %rd107;
	add.s64 	%rd110, %rd108, %rd91;
	st.global.v4.b32 	[%rd110], {%r134, %r135, %r136, %r137};
	ret;

}
    kernels_cuModule_0_ptx_data 